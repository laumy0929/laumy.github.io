<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ONNX Runtime Python端侧模型部署YOLOv5 - Laumy的技术栈</title>
    <link rel="stylesheet" href="../assets/style.css">
    <!-- MathJax支持LaTeX数学公式 -->
    <script>
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          ignoreHtmlClass: 'tex2jax_ignore',
          processHtmlClass: 'tex2jax_process'
        }
      };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body>
    <header class="site-header">
      <div class="container">
        <a class="logo" href="../">Laumy的技术栈</a>
        <div class="search">
          <input id="search-input" type="text" placeholder="输入关键词回车搜索">
        </div>
        <div class="theme-toggle" title="切换主题" id="theme-toggle">☾</div>
        <nav class="top-nav">
          <div class="nav-item"><a href="../">首页</a></div>
        </nav>
      </div>
    </header>

    <main class="container layout">
      <aside class="left-nav">
        
        <div class="card">
          <div class="card-title">文章目录</div>
          <nav id="toc"><ul><li><a href="#onnx-runtime">ONNX Runtime介绍</a><ul><li><a href="#_1">加载模型</a></li><li><a href="#_2">模型推理</a></li></ul></li><li><a href="#yolov5">YOLOv5运行示例</a><ul><li><a href="#_3">加载模型</a></li><li><a href="#_4">图像预处理</a></li><li><a href="#_5">模型推理</a></li><li><a href="#_6">模型后处理</a></li></ul></li></ul></nav>
        </div>
        
      </aside>

      <section class="content">
        
<article class="card post">
  <h1>ONNX Runtime Python端侧模型部署YOLOv5</h1>
  <div class="meta">2025-06-18 · ai</div>
  <div class="post-content"><h2 id="onnx-runtime">ONNX Runtime介绍</h2>
<p>ONNX Runtime不依赖于Pytorch、tensorflow等机器学习训练模型框架。他提供了一种简单的方法，可以在CPU、GPU、NPU上运行模型。通常ONNX Runtime用于端侧设备模型的运行推理。要使用ONNX Runtime运行模型，一般的步骤如下：</p>
<ul>
<li>用你最喜欢的框架（如pytorch、tensorflow、paddle等）训练一个模型。</li>
<li>将模型转换或导出为ONNX格式。</li>
<li>在端侧使用ONNX Runtime加载并运行模型。</li>
</ul>
<p>模型的训练和导出为ONNX格式这里就不再阐述了。下面基于python在端侧运行模型的示例：</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span>
<span class="c1"># 导入numpy模块</span>
<span class="kn">import</span> <span class="nn">onnxruntime</span> <span class="k">as</span> <span class="nn">rt</span>
<span class="c1"># 导入onnxruntime模块</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">rt</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
    <span class="s2">"logreg_iris.onnx"</span><span class="p">,</span> <span class="n">providers</span><span class="o">=</span><span class="n">rt</span><span class="o">.</span><span class="n">get_available_providers</span><span class="p">())</span>
<span class="c1"># 加载模型logreg_iris.onnx</span>

<span class="n">input_name</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
<span class="c1"># 获取模型的输入名称，对应的是使用https://netron.app/中intput name。</span>

<span class="n">pred_onx</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)})[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># 运行模型推理，返回结果到pred_onx中</span>

<span class="nb">print</span><span class="p">(</span><span class="n">pred_onx</span><span class="p">)</span>
</code></pre></div>
<p>上面给出的python示例中，端侧运行模型可以总结为2个步骤。加载模型，模型推理。</p>
<h3 id="_1">加载模型</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
    <span class="n">path_or_bytes</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">bytes</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">,</span>
    <span class="n">sess_options</span><span class="p">:</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">SessionOptions</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">providers</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">provider_options</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>path_or_bytes： 模型文件名或者ONNX、ORT格式二进制。</li>
<li>sess_options： 会话选项，比如配置线程数、优先级。</li>
<li>providers： 指定执行提供者优先级（['CUDAExecutionProvider','CPUExecutionProvider']）</li>
<li>provider_options： 字典序列，为每个提供者配置专属参数（如CUDA设备ID）</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="n">options</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">SessionOptions</span><span class="p">()</span>
<span class="n">options</span><span class="o">.</span><span class="n">SetIntraOpNumThreads</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># 多设备优先级配置</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span>
    <span class="s2">"model.onnx"</span><span class="p">,</span>
    <span class="n">sess_options</span><span class="o">=</span><span class="n">options</span><span class="p">,</span>
    <span class="n">providers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">'CUDAExecutionProvider'</span><span class="p">,</span> <span class="p">{</span><span class="s1">'device_id'</span><span class="p">:</span> <span class="mi">0</span><span class="p">}),</span>
        <span class="s1">'CPUExecutionProvider'</span>
    <span class="p">]</span>
<span class="p">)</span>
</code></pre></div>
<h3 id="_2">模型推理</h3>
<div class="codehilite"><pre><span></span><code><span class="n">outputs</span> <span class="o">=</span> <span class="n">senssion</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output_names</span><span class="p">,</span> <span class="n">input_feed</span><span class="p">,</span> <span class="n">run_options</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>output_names:输出节点名称，字符串列表,指定需要获取的输出节点名称，若为None则返回所有输出</li>
<li>input_feed:输入数据，字典类型，结构为{"输入节点名": numpy数组/ORTValue}，建议使用ORTValue封装输入数据以减少CPU-GPU拷贝开销。</li>
<li>run_options:运行参数，如日志级别。</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnxruntime</span> <span class="k">as</span> <span class="nn">ort</span>

<span class="c1"># 创建示例数据</span>
<span class="n">cpu_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># 转换为GPU上的ORTValue</span>
<span class="n">gpu_ort_value</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">OrtValue</span><span class="o">.</span><span class="n">ortvalue_from_numpy</span><span class="p">(</span>
    <span class="n">cpu_data</span><span class="p">,</span>
    <span class="n">device_type</span><span class="o">=</span><span class="s1">'cuda'</span><span class="p">,</span>  <span class="c1"># 关键参数：指定GPU设备</span>
    <span class="n">device_id</span><span class="o">=</span><span class="mi">0</span>         <span class="c1"># GPU设备ID（多卡时指定）</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">gpu_ort_value</span><span class="o">.</span><span class="n">device_name</span><span class="p">())</span>  <span class="c1"># 输出: 'Cuda'</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">"output_name"</span><span class="p">],</span>
    <span class="p">{</span><span class="s2">"input_name"</span><span class="p">:</span> <span class="n">gpu_ort_value</span><span class="p">}</span>  <span class="c1"># 避免CPU-&gt;GPU拷贝</span>
<span class="p">)</span>
</code></pre></div>
<p>在运行模型是，需要获取模型的输入和输出名称，可以通过调用对应的函数session.get_inputs(),session.get_outputs()来获取。inputs和outputs函数返回的是onnxruntime.NodeArg类，该类是ONNX Runtime中表示计算图节点输入/输出参数的核心类，该类有3个成员变量，如下：</p>
<ul>
<li>property name： 参数唯一标识符，对应计算图中的节点名称。</li>
<li>property shape： 张量形状。</li>
<li>property type：数据类型（如tensor(float32)/tensor(int64)）</li>
</ul>
<p>以下是获取输入名称和输出名称的示例。</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_name</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
<span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">session</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()]</span>
</code></pre></div>
<p>详细请参考：<a href="https://onnxruntime.ai/docs/api/python/api_summary.html">https://onnxruntime.ai/docs/api/python/api_summary.html</a></p>
<h2 id="yolov5">YOLOv5运行示例</h2>
<h3 id="_3">加载模型</h3>
<div class="codehilite"><pre><span></span><code><span class="n">session_options</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">SessionOptions</span><span class="p">()</span>
<span class="n">session_options</span><span class="o">.</span><span class="n">intra_op_num_threads</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># 加载 ONNX 模型</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
        <span class="s2">"yolov5_n.q.onnx"</span><span class="p">,</span>
        <span class="n">sess_options</span><span class="o">=</span><span class="n">session_options</span><span class="p">,</span>
        <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s2">"XXXExecutionProvider"</span><span class="p">])</span>
</code></pre></div>
<p>创建SessionOptions对象用于定制化会话行为，限制算子内部并行线程数为1，加载名为yolov5_n.q.onnx的量化版YOLOv5模型，指定自定义执行提供者XXXExecutionProvider。</p>
<h3 id="_4">图像预处理</h3>
<div class="codehilite"><pre><span></span><code><span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">image</span><span class="p">)</span>
<span class="c1">#image shape (375, 500, 3)</span>

<span class="n">image_shape</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span class="c1">#image_shape的值(375, 500)，取前面2个值为图像的宽高</span>

<span class="c1"># 获取图像的尺寸大小高和宽。</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># 图像预处理函数</span>
<span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="p">(</span><span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">)):</span>
    <span class="c1"># 调整图像大小为640*640，</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span>
    <span class="c1"># 转换颜色空间RGB</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>

    <span class="c1"># 归一化处理</span>
    <span class="c1">#astype(np.float32)将图像像素值从整数类型（如uint8）转换为32位浮点数，</span>
    <span class="c1">#避免后续除法运算的精度损失，/ 255.0将像素值从[0,255]的原始范围线性映射到[0,1]区间，</span>
    <span class="c1">#符合神经网络输入的典型数值范围要求</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>

    <span class="c1"># 转置模型为CHW格式，原输入是HWC格式。</span>
    <span class="c1"># 输入的数据是（640，640，3），需要调整为NCHW模型格式 [batch, channel, height, width]</span>
    <span class="c1"># 使用np.transpose进行转置，变换成（3，640，640）</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># 接着再加上一个轴变化成（1，3，640，640）tensor。</span>
    <span class="k">return</span> <span class="n">image</span>
</code></pre></div>
<p><a href="https://www.laumy.tech/wp-content/uploads/2025/06/wp_editor_md_a085673644d5a2a3b34c1e9635b98c0e.jpg"><img alt="" src="assets/doc/04-ai/ai应用/端侧onnx-runtime-python模型推理/images/wp_editor_md_a085673644d5a2a3b34c1e9635b98c0e.jpg"/></a></p>
<p>如何理解深度学习中的轴了？ 在深度学习中，轴可以理解为维度。如上图是一个NCHW排布的格式，把N当成第一个维度即位轴0，C第二维度即为轴1，H第三维度即为轴2，W为第四维度即为轴3。np.expand_dims(image, axis=0)即拓展了轴0，原来只有3个维度现在变成4个维度了，N为1。还可以按照指定的轴进行求和，即做压缩。执行np.sum(data, axis=0)时，也就是沿着N的维度就行压缩求和，就变成如上图。由原来的（N,C,W,H）变成了(C',W',H'),即N个CWH中的各自相加。如果是np.sum(data,axis=1)，那就是按照C维度方向进行相加，结果就是（N,W,H）,即如RGB格式就是每个图像RGB 3通道的像素相加，如下图所示。</p>
<p><a href="https://www.laumy.tech/wp-content/uploads/2025/06/wp_editor_md_7eb3980a9c98c242d3ac6e8e422fa18f.jpg"><img alt="" src="assets/doc/04-ai/ai应用/端侧onnx-runtime-python模型推理/images/wp_editor_md_7eb3980a9c98c242d3ac6e8e422fa18f.jpg"/></a></p>
<h3 id="_5">模型推理</h3>
<p>模型推理前，需要获取计算图输入和输入的名称</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_name</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
<span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">session</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">()]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'input name'</span><span class="p">,</span> <span class="n">input_name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'output name'</span><span class="p">,</span> <span class="n">output_names</span><span class="p">)</span>
</code></pre></div>
<p>输出结果与下图对应。</p>
<div class="codehilite"><pre><span></span><code><span class="nb">input</span> <span class="n">name</span> <span class="nb">input</span>
<span class="n">output</span> <span class="n">name</span> <span class="p">[</span><span class="s1">'dets'</span><span class="p">,</span> <span class="s1">'labels'</span><span class="p">]</span>
</code></pre></div>
<p><a href="https://www.laumy.tech/wp-content/uploads/2025/06/wp_editor_md_0031f187b9e1a6957df1a42c8444329f.jpg"><img alt="" src="assets/doc/04-ai/ai应用/端侧onnx-runtime-python模型推理/images/wp_editor_md_0031f187b9e1a6957df1a42c8444329f.jpg"/></a></p>
<p>获取到intput_name和ouput_names后，即可调用运行推理。</p>
<div class="codehilite"><pre><span></span><code><span class="n">outputs</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output_names</span><span class="p">,</span> <span class="p">{</span><span class="n">input_name</span><span class="p">:</span> <span class="n">input_tensor</span><span class="p">})</span>
</code></pre></div>
<h3 id="_6">模型后处理</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># 把batch这个维度去掉</span>
<span class="n">dets</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">labels_pred</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

<span class="c1">#将坐标进行缩放以适应实际图片的大小。</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">)</span>
<span class="n">scale_x</span> <span class="o">=</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">scale_y</span> <span class="o">=</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">input_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">dets</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scale_x</span>
<span class="n">dets</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scale_y</span>
<span class="n">dets</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scale_x</span>
<span class="n">dets</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scale_y</span>
</code></pre></div>
<p>模型outputs有两个输出，一个是dets，这是一个二位数组dets[n][5],其中det[5]包含了坐标x1, y1, x2, y2，score,前面4个预选框的坐标，后面一个为预选框的分数。</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">visualize_results</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dets</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">conf_threshold</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dets</span><span class="p">)):</span>
        <span class="n">det</span> <span class="o">=</span> <span class="n">dets</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">det</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="c1">#每个框的分数</span>
        <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">conf_threshold</span><span class="p">:</span> <span class="c1">#小于分数的剔除</span>
            <span class="n">class_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">det</span><span class="p">[:</span><span class="mi">4</span><span class="p">])</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">class_id</span><span class="p">]</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">),</span> <span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">-</span> <span class="mi">10</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span>
</code></pre></div>
<p>根据阈值分数进行画框，最终完成结果的后处理，注意上面并没有进行极大值抑制。</p></div>
  <div class="post-nav">
    <a class="prev" href="../onnx-runtime-c-端侧模型部署yolov5.html">← ONNX Runtime C++端侧模型部署YOLOv5</a>
    <a class="next" href="../端侧vscode-ai开发环境搭建.html">端侧vscode AI开发环境搭建 →</a>
  </div>
</article>

      </section>

      <aside class="right-panel">
        
      </aside>
    </main>

    <footer class="site-footer">
      <div class="container">Copyright ©2022-2025 laumy 版权所有</div>
    </footer>

    <script src="../assets/site.js"></script>
  </body>
  </html>

